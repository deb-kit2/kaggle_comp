{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "plant_pathology.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMCP6rSaqjwIEJhX0ge6ser",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deb-kit2/kaggle_comp/blob/master/plant_pathology/plant_pathology.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1y6yQuFGe0H",
        "colab_type": "code",
        "outputId": "3401542d-e8a6-4406-e0ac-5c4e0a857109",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/plant_pathology_kaggle\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfF69T_vII5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "sam_sub = pd.read_csv('sample_submission.csv')\n",
        "train_csv = pd.read_csv('train.csv')\n",
        "test_csv = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLspOwtTY4W3",
        "colab_type": "code",
        "outputId": "8c78d14c-c9db-4fbc-f25b-dbb9f81d2972",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_csv.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>healthy</th>\n",
              "      <th>multiple_diseases</th>\n",
              "      <th>rust</th>\n",
              "      <th>scab</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Train_0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Train_1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Train_2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Train_3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Train_4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image_id  healthy  multiple_diseases  rust  scab\n",
              "0  Train_0        0                  0     0     1\n",
              "1  Train_1        0                  1     0     0\n",
              "2  Train_2        1                  0     0     0\n",
              "3  Train_3        0                  0     1     0\n",
              "4  Train_4        1                  0     0     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CwyCE43aAvK",
        "colab_type": "code",
        "outputId": "1a796a5d-2be5-4c12-dd41-a7143228b1c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "def get_class(row): \n",
        "  if row['multiple_diseases'] == 1: \n",
        "    return 'multiple_diseases' \n",
        "  elif row['rust'] == 1: \n",
        "    return 'rust' \n",
        "  elif row['scab'] == 1: \n",
        "    return 'scab' \n",
        "  else: \n",
        "    return 'healthy' \n",
        "    \n",
        "train_csv[\"label\"] = train_csv.apply(get_class, axis=1) \n",
        "#train_csv.head()\n",
        "temp = pd.factorize(train_csv[\"label\"])\n",
        "train_csv[\"label\"] = temp[0]\n",
        "\n",
        "train_csv.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>healthy</th>\n",
              "      <th>multiple_diseases</th>\n",
              "      <th>rust</th>\n",
              "      <th>scab</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Train_0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Train_1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Train_2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Train_3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Train_4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image_id  healthy  multiple_diseases  rust  scab  label\n",
              "0  Train_0        0                  0     0     1      0\n",
              "1  Train_1        0                  1     0     0      1\n",
              "2  Train_2        1                  0     0     0      2\n",
              "3  Train_3        0                  0     1     0      3\n",
              "4  Train_4        1                  0     0     0      2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlU_7tD1abwA",
        "colab_type": "code",
        "outputId": "32f4b2f2-0367-4792-8859-ccdbccd22004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "reference_map = {\"scab\" : 0, \"multiple_diseases\" : 1, \"healthy\" : 2, \"rust\" : 3}\n",
        "y = train_csv[\"label\"]\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "y = to_categorical(y, 4)\n",
        "y"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9fwjtEebUA4",
        "colab_type": "code",
        "outputId": "2c897712-3452-4182-8a94-719c202ae8c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_csv.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Test_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Test_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Test_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Test_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Test_4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image_id\n",
              "0   Test_0\n",
              "1   Test_1\n",
              "2   Test_2\n",
              "3   Test_3\n",
              "4   Test_4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1EQEzuWayzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/plant_pathology_kaggle/images/'\n",
        "image_list = os.listdir(path)\n",
        "\n",
        "train_images = train_csv[\"image_id\"]\n",
        "test_images = test_csv[\"image_id\"]\n",
        "\n",
        "train_images = np.asarray(train_images) + \".jpg\"\n",
        "test_images = np.asarray(test_images) + \".jpg\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0RitlPVdRee",
        "colab_type": "code",
        "outputId": "512bfcf9-2469-4031-e165-a4703d2242e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_images"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Train_0.jpg', 'Train_1.jpg', 'Train_2.jpg', ..., 'Train_1818.jpg',\n",
              "       'Train_1819.jpg', 'Train_1820.jpg'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5k0_E5kb6Ps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "22274841-0870-4d6d-9773-ffa7a50abc7b"
      },
      "source": [
        "image_height = 150\n",
        "image_width = 150\n",
        "channels = 3\n",
        "\n",
        "import cv2\n",
        "xtrain = np.zeros((len(y), image_height, image_width, channels))\n",
        "xtest = np.zeros((len(y), image_height, image_width, channels))\n",
        "\n",
        "for i in range(len(y)):\n",
        "  imgtrain = train_images[i]\n",
        "  imgtest = test_images[i]\n",
        "  #path = '/content/drive/My Drive/plant_pathology_kaggle/images/' + img\n",
        "  img = cv2.imread('/content/drive/My Drive/plant_pathology_kaggle/images/'+imgtrain)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img, (image_height, image_width))\n",
        "  xtrain[i] = img\n",
        "  img = cv2.imread('/content/drive/My Drive/plant_pathology_kaggle/images/'+imgtest)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img, (image_height, image_width))\n",
        "  xtest[i] = img\n",
        "\n",
        "\"\"\"\n",
        "for i in range(len(y)):\n",
        "  img = test_images[i]\n",
        "  path = '/content/drive/My Drive/plant_pathology_kaggle/images/' + img\n",
        "  img = cv2.imread(path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img, (image_height, image_width))\n",
        "  xtest[i] = img\n",
        "\"\"\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfor i in range(len(y)):\\n  img = test_images[i]\\n  path = '/content/drive/My Drive/plant_pathology_kaggle/images/' + img\\n  img = cv2.imread(path)\\n  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\\n  img = cv2.resize(img, (image_height, image_width))\\n  xtest[i] = img\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJChdIYWeCsf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "74637543-45c4-4f09-b0f1-05a315de31c9"
      },
      "source": [
        "print(xtrain.shape)\n",
        "print(xtest.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1821, 150, 150, 3)\n",
            "(1821, 150, 150, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFSyaeG2hSpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain /= 255\n",
        "xtest /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvFt_UxT555e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "2359629b-3233-4817-da47-23e498a8a81b"
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "ros = RandomOverSampler(random_state = 267)\n",
        "\n",
        "x_res, y_res = ros.fit_resample(xtrain.reshape((-1, image_height * image_width * channels)), y)\n",
        "x_res = x_res.reshape((-1, image_height, image_width, channels))\n",
        "\n",
        "x_res.shape, y_res.sum(axis=0)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2488, 150, 150, 3), array([622, 622, 622, 622]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDxiFVcph42m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xtrain, xcv, ytrain, ycv = train_test_split(x_res, y_res, test_size = 0.1, random_state = 267)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FREO0ZHdjSIP",
        "colab_type": "text"
      },
      "source": [
        "####Thats all basic pre-procesing.\n",
        "Things to try next : \n",
        "  #iii. transfer learning\n",
        "  #iv. without reshaping "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhM9IazpjOmp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "e4450bd5-9861-4945-c88d-2b949bb4622c"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3,3), padding = \"same\", \n",
        "                 activation = \"relu\", input_shape = (image_height, image_width, channels)))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "#model.add(MaxPool2D(pool_size=(2,2)))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = \"same\", \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "#model.add(MaxPool2D(pool_size=(2,2)))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = \"same\", \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = \"same\", \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "#model.add(Conv2D(filters = 256, kernel_size = (3,3),padding = \"same\", \n",
        "#                 activation ='relu'))\n",
        "#model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "#model.add(Conv2D(filters = 512, kernel_size = (3,3),padding = \"same\", \n",
        "#                 activation ='relu'))\n",
        "#model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation = \"relu\"))\n",
        "#model.add(Dropout(0.5))\n",
        "model.add(Dense(4, activation = \"softmax\"))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5UI4e09nG-K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "87ce20c3-167d-4ff8-f066-56880606a31d"
      },
      "source": [
        "from keras.optimizers import RMSprop\n",
        "opti = RMSprop(lr = 1e-3)\n",
        "model.compile(optimizer = opti, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, \n",
        "                                            verbose=1, factor=0.5, min_lr = 1e-10)\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(filepath = \"/content/res_aug.h5\", \n",
        "                             save_best_only = True, monitor = \"val_loss\",\n",
        "                             verbose = 1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xovH2SZ-UgYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(rotation_range = 45, width_shift_range = 0.2, height_shift_range = 0.2,\n",
        "                             zoom_range = 0.2, horizontal_flip = True, vertical_flip = True)\n",
        "\n",
        "datagen.fit(xtrain)\n",
        "\n",
        "train_size = len(ytrain)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdWLol8on9sk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e203e9b0-2cf2-4a44-de76-2a3f648036d3"
      },
      "source": [
        "history = model.fit_generator(datagen.flow(x = xtrain, y = ytrain, batch_size = 32), \n",
        "                    epochs = 100, steps_per_epoch = train_size//32, \n",
        "                    validation_data = (xcv, ycv), \n",
        "                    callbacks = [learning_rate_reduction, checkpoint])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "69/69 [==============================] - 67s 971ms/step - loss: 1.6090 - acc: 0.2574 - val_loss: 1.3847 - val_acc: 0.2530\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.38468, saving model to /content/res_aug.h5\n",
            "Epoch 2/100\n",
            "69/69 [==============================] - 66s 957ms/step - loss: 1.3949 - acc: 0.2628 - val_loss: 1.3810 - val_acc: 0.3173\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.38468 to 1.38096, saving model to /content/res_aug.h5\n",
            "Epoch 3/100\n",
            "69/69 [==============================] - 66s 956ms/step - loss: 1.3887 - acc: 0.2524 - val_loss: 1.3915 - val_acc: 0.2570\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.38096\n",
            "Epoch 4/100\n",
            "69/69 [==============================] - 66s 950ms/step - loss: 1.3989 - acc: 0.2899 - val_loss: 1.3618 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.38096 to 1.36180, saving model to /content/res_aug.h5\n",
            "Epoch 5/100\n",
            "69/69 [==============================] - 66s 951ms/step - loss: 1.4665 - acc: 0.2944 - val_loss: 1.3183 - val_acc: 0.3655\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.36180 to 1.31831, saving model to /content/res_aug.h5\n",
            "Epoch 6/100\n",
            "69/69 [==============================] - 66s 951ms/step - loss: 1.3570 - acc: 0.3221 - val_loss: 1.3294 - val_acc: 0.3454\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.31831\n",
            "Epoch 7/100\n",
            "69/69 [==============================] - 66s 950ms/step - loss: 1.3376 - acc: 0.3741 - val_loss: 1.2318 - val_acc: 0.4257\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.31831 to 1.23184, saving model to /content/res_aug.h5\n",
            "Epoch 8/100\n",
            "69/69 [==============================] - 65s 948ms/step - loss: 1.2476 - acc: 0.4275 - val_loss: 1.0977 - val_acc: 0.5542\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.23184 to 1.09768, saving model to /content/res_aug.h5\n",
            "Epoch 9/100\n",
            "69/69 [==============================] - 66s 963ms/step - loss: 1.1118 - acc: 0.5093 - val_loss: 0.8880 - val_acc: 0.6145\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.09768 to 0.88800, saving model to /content/res_aug.h5\n",
            "Epoch 10/100\n",
            "69/69 [==============================] - 66s 954ms/step - loss: 1.0220 - acc: 0.5414 - val_loss: 0.9338 - val_acc: 0.6386\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.88800\n",
            "Epoch 11/100\n",
            "69/69 [==============================] - 66s 954ms/step - loss: 0.9460 - acc: 0.5773 - val_loss: 0.9248 - val_acc: 0.5582\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.88800\n",
            "Epoch 12/100\n",
            "69/69 [==============================] - 66s 954ms/step - loss: 0.9348 - acc: 0.5954 - val_loss: 0.7256 - val_acc: 0.6787\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.88800 to 0.72561, saving model to /content/res_aug.h5\n",
            "Epoch 13/100\n",
            "69/69 [==============================] - 66s 955ms/step - loss: 0.8796 - acc: 0.6067 - val_loss: 0.8496 - val_acc: 0.5984\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.72561\n",
            "Epoch 14/100\n",
            "69/69 [==============================] - 66s 955ms/step - loss: 0.8503 - acc: 0.6185 - val_loss: 0.6910 - val_acc: 0.7068\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.72561 to 0.69104, saving model to /content/res_aug.h5\n",
            "Epoch 15/100\n",
            "69/69 [==============================] - 66s 954ms/step - loss: 0.8386 - acc: 0.6448 - val_loss: 0.9419 - val_acc: 0.6104\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.69104\n",
            "Epoch 16/100\n",
            "69/69 [==============================] - 66s 953ms/step - loss: 0.7926 - acc: 0.6593 - val_loss: 0.6417 - val_acc: 0.7590\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.69104 to 0.64169, saving model to /content/res_aug.h5\n",
            "Epoch 17/100\n",
            "69/69 [==============================] - 66s 953ms/step - loss: 0.7897 - acc: 0.6569 - val_loss: 0.5980 - val_acc: 0.7510\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.64169 to 0.59795, saving model to /content/res_aug.h5\n",
            "Epoch 18/100\n",
            "69/69 [==============================] - 66s 952ms/step - loss: 0.7723 - acc: 0.6898 - val_loss: 0.7023 - val_acc: 0.6988\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.59795\n",
            "Epoch 19/100\n",
            "69/69 [==============================] - 66s 954ms/step - loss: 0.7568 - acc: 0.6831 - val_loss: 0.5626 - val_acc: 0.7631\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.59795 to 0.56261, saving model to /content/res_aug.h5\n",
            "Epoch 20/100\n",
            "69/69 [==============================] - 66s 958ms/step - loss: 0.7116 - acc: 0.6983 - val_loss: 0.5227 - val_acc: 0.7952\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.56261 to 0.52271, saving model to /content/res_aug.h5\n",
            "Epoch 21/100\n",
            "69/69 [==============================] - 66s 959ms/step - loss: 0.7175 - acc: 0.7154 - val_loss: 0.6215 - val_acc: 0.7390\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.52271\n",
            "Epoch 22/100\n",
            "69/69 [==============================] - 66s 957ms/step - loss: 0.6483 - acc: 0.7405 - val_loss: 0.6268 - val_acc: 0.7349\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.52271\n",
            "Epoch 23/100\n",
            "69/69 [==============================] - 67s 969ms/step - loss: 0.6445 - acc: 0.7448 - val_loss: 0.5273 - val_acc: 0.8273\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.52271\n",
            "Epoch 24/100\n",
            "69/69 [==============================] - 66s 959ms/step - loss: 0.6359 - acc: 0.7450 - val_loss: 0.5644 - val_acc: 0.7992\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.52271\n",
            "Epoch 25/100\n",
            "69/69 [==============================] - 66s 957ms/step - loss: 0.6039 - acc: 0.7643 - val_loss: 0.6324 - val_acc: 0.7430\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.52271\n",
            "Epoch 26/100\n",
            "69/69 [==============================] - 66s 954ms/step - loss: 0.5934 - acc: 0.7686 - val_loss: 0.6494 - val_acc: 0.7309\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.52271\n",
            "Epoch 27/100\n",
            "69/69 [==============================] - 66s 952ms/step - loss: 0.4598 - acc: 0.8210 - val_loss: 0.3956 - val_acc: 0.8675\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.52271 to 0.39562, saving model to /content/res_aug.h5\n",
            "Epoch 28/100\n",
            "69/69 [==============================] - 66s 954ms/step - loss: 0.4328 - acc: 0.8395 - val_loss: 0.3868 - val_acc: 0.8675\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.39562 to 0.38679, saving model to /content/res_aug.h5\n",
            "Epoch 29/100\n",
            "69/69 [==============================] - 66s 959ms/step - loss: 0.4236 - acc: 0.8432 - val_loss: 0.4138 - val_acc: 0.8675\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.38679\n",
            "Epoch 30/100\n",
            "69/69 [==============================] - 66s 956ms/step - loss: 0.4012 - acc: 0.8510 - val_loss: 0.3449 - val_acc: 0.8755\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.38679 to 0.34493, saving model to /content/res_aug.h5\n",
            "Epoch 31/100\n",
            "69/69 [==============================] - 66s 956ms/step - loss: 0.4163 - acc: 0.8491 - val_loss: 0.3615 - val_acc: 0.8916\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.34493\n",
            "Epoch 32/100\n",
            "69/69 [==============================] - 66s 957ms/step - loss: 0.4103 - acc: 0.8464 - val_loss: 0.3858 - val_acc: 0.8795\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.34493\n",
            "Epoch 33/100\n",
            "69/69 [==============================] - 66s 958ms/step - loss: 0.4075 - acc: 0.8424 - val_loss: 0.3108 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.34493 to 0.31081, saving model to /content/res_aug.h5\n",
            "Epoch 34/100\n",
            "69/69 [==============================] - 66s 962ms/step - loss: 0.3701 - acc: 0.8586 - val_loss: 0.3221 - val_acc: 0.8876\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.31081\n",
            "Epoch 35/100\n",
            "69/69 [==============================] - 66s 960ms/step - loss: 0.3928 - acc: 0.8546 - val_loss: 0.4222 - val_acc: 0.8514\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.31081\n",
            "Epoch 36/100\n",
            "69/69 [==============================] - 66s 960ms/step - loss: 0.3662 - acc: 0.8591 - val_loss: 0.4142 - val_acc: 0.8434\n",
            "\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.31081\n",
            "Epoch 37/100\n",
            "69/69 [==============================] - 67s 968ms/step - loss: 0.3108 - acc: 0.8958 - val_loss: 0.2805 - val_acc: 0.9076\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.31081 to 0.28046, saving model to /content/res_aug.h5\n",
            "Epoch 38/100\n",
            "69/69 [==============================] - 66s 962ms/step - loss: 0.3221 - acc: 0.8868 - val_loss: 0.2682 - val_acc: 0.9076\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.28046 to 0.26822, saving model to /content/res_aug.h5\n",
            "Epoch 39/100\n",
            "69/69 [==============================] - 66s 961ms/step - loss: 0.2720 - acc: 0.8934 - val_loss: 0.2926 - val_acc: 0.9076\n",
            "\n",
            "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.26822\n",
            "Epoch 40/100\n",
            "69/69 [==============================] - 66s 958ms/step - loss: 0.2694 - acc: 0.8972 - val_loss: 0.2817 - val_acc: 0.9076\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.26822\n",
            "Epoch 41/100\n",
            "69/69 [==============================] - 66s 955ms/step - loss: 0.2710 - acc: 0.8990 - val_loss: 0.2646 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.26822 to 0.26464, saving model to /content/res_aug.h5\n",
            "Epoch 42/100\n",
            "69/69 [==============================] - 66s 954ms/step - loss: 0.2616 - acc: 0.9058 - val_loss: 0.2707 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.26464\n",
            "Epoch 43/100\n",
            "69/69 [==============================] - 66s 952ms/step - loss: 0.2651 - acc: 0.9053 - val_loss: 0.2616 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.26464 to 0.26162, saving model to /content/res_aug.h5\n",
            "Epoch 44/100\n",
            "69/69 [==============================] - 66s 950ms/step - loss: 0.2337 - acc: 0.9112 - val_loss: 0.2616 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00044: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.26162 to 0.26158, saving model to /content/res_aug.h5\n",
            "Epoch 45/100\n",
            "69/69 [==============================] - 66s 951ms/step - loss: 0.2414 - acc: 0.9153 - val_loss: 0.2554 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.26158 to 0.25539, saving model to /content/res_aug.h5\n",
            "Epoch 46/100\n",
            "69/69 [==============================] - 66s 951ms/step - loss: 0.2361 - acc: 0.9180 - val_loss: 0.2310 - val_acc: 0.9237\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.25539 to 0.23097, saving model to /content/res_aug.h5\n",
            "Epoch 47/100\n",
            "69/69 [==============================] - 66s 951ms/step - loss: 0.2199 - acc: 0.9153 - val_loss: 0.2514 - val_acc: 0.9076\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.23097\n",
            "Epoch 48/100\n",
            "69/69 [==============================] - 66s 953ms/step - loss: 0.2378 - acc: 0.9153 - val_loss: 0.2375 - val_acc: 0.9277\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.23097\n",
            "Epoch 49/100\n",
            "69/69 [==============================] - 65s 949ms/step - loss: 0.2330 - acc: 0.9189 - val_loss: 0.2249 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.23097 to 0.22490, saving model to /content/res_aug.h5\n",
            "Epoch 50/100\n",
            "69/69 [==============================] - 66s 952ms/step - loss: 0.2311 - acc: 0.9207 - val_loss: 0.2432 - val_acc: 0.9237\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.22490\n",
            "Epoch 51/100\n",
            "69/69 [==============================] - 66s 954ms/step - loss: 0.2225 - acc: 0.9230 - val_loss: 0.2357 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00051: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.22490\n",
            "Epoch 52/100\n",
            "69/69 [==============================] - 66s 952ms/step - loss: 0.2197 - acc: 0.9225 - val_loss: 0.2291 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.22490\n",
            "Epoch 53/100\n",
            "69/69 [==============================] - 66s 953ms/step - loss: 0.2270 - acc: 0.9235 - val_loss: 0.2339 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.22490\n",
            "Epoch 54/100\n",
            "69/69 [==============================] - 66s 952ms/step - loss: 0.1883 - acc: 0.9320 - val_loss: 0.2392 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.22490\n",
            "Epoch 55/100\n",
            "69/69 [==============================] - 66s 951ms/step - loss: 0.2095 - acc: 0.9265 - val_loss: 0.2339 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.22490\n",
            "Epoch 56/100\n",
            "69/69 [==============================] - 66s 951ms/step - loss: 0.1875 - acc: 0.9321 - val_loss: 0.2334 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.22490\n",
            "Epoch 57/100\n",
            "69/69 [==============================] - 66s 952ms/step - loss: 0.2122 - acc: 0.9252 - val_loss: 0.2303 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.22490\n",
            "Epoch 58/100\n",
            "69/69 [==============================] - 66s 950ms/step - loss: 0.1986 - acc: 0.9357 - val_loss: 0.2290 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.22490\n",
            "Epoch 59/100\n",
            "69/69 [==============================] - 66s 950ms/step - loss: 0.2140 - acc: 0.9176 - val_loss: 0.2304 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.22490\n",
            "Epoch 60/100\n",
            "69/69 [==============================] - 66s 950ms/step - loss: 0.2085 - acc: 0.9279 - val_loss: 0.2324 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00060: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.22490\n",
            "Epoch 61/100\n",
            "69/69 [==============================] - 66s 951ms/step - loss: 0.1969 - acc: 0.9312 - val_loss: 0.2306 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.22490\n",
            "Epoch 62/100\n",
            "69/69 [==============================] - 66s 963ms/step - loss: 0.2177 - acc: 0.9252 - val_loss: 0.2295 - val_acc: 0.9197\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.22490\n",
            "Epoch 63/100\n",
            "69/69 [==============================] - 66s 955ms/step - loss: 0.1993 - acc: 0.9284 - val_loss: 0.2275 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.22490\n",
            "Epoch 64/100\n",
            "69/69 [==============================] - 66s 957ms/step - loss: 0.2019 - acc: 0.9230 - val_loss: 0.2262 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.22490\n",
            "Epoch 65/100\n",
            "69/69 [==============================] - 66s 961ms/step - loss: 0.2083 - acc: 0.9225 - val_loss: 0.2248 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.22490 to 0.22484, saving model to /content/res_aug.h5\n",
            "Epoch 66/100\n",
            "69/69 [==============================] - 66s 956ms/step - loss: 0.2090 - acc: 0.9275 - val_loss: 0.2255 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00066: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.22484\n",
            "Epoch 67/100\n",
            "69/69 [==============================] - 66s 959ms/step - loss: 0.2137 - acc: 0.9252 - val_loss: 0.2255 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.22484\n",
            "Epoch 68/100\n",
            "69/69 [==============================] - 66s 956ms/step - loss: 0.2113 - acc: 0.9194 - val_loss: 0.2256 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.22484\n",
            "Epoch 69/100\n",
            "69/69 [==============================] - 66s 957ms/step - loss: 0.2179 - acc: 0.9280 - val_loss: 0.2254 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00069: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.22484\n",
            "Epoch 70/100\n",
            "69/69 [==============================] - 66s 958ms/step - loss: 0.2018 - acc: 0.9243 - val_loss: 0.2255 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.22484\n",
            "Epoch 71/100\n",
            "69/69 [==============================] - 65s 949ms/step - loss: 0.2015 - acc: 0.9293 - val_loss: 0.2255 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.22484\n",
            "Epoch 72/100\n",
            "69/69 [==============================] - 66s 955ms/step - loss: 0.2028 - acc: 0.9279 - val_loss: 0.2253 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00072: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.22484\n",
            "Epoch 73/100\n",
            "69/69 [==============================] - 66s 954ms/step - loss: 0.2111 - acc: 0.9257 - val_loss: 0.2253 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.22484\n",
            "Epoch 74/100\n",
            "69/69 [==============================] - 66s 956ms/step - loss: 0.2146 - acc: 0.9225 - val_loss: 0.2251 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.22484\n",
            "Epoch 75/100\n",
            "69/69 [==============================] - 66s 957ms/step - loss: 0.2150 - acc: 0.9252 - val_loss: 0.2251 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00075: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.22484\n",
            "Epoch 76/100\n",
            "69/69 [==============================] - 66s 959ms/step - loss: 0.1986 - acc: 0.9284 - val_loss: 0.2251 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.22484\n",
            "Epoch 77/100\n",
            "69/69 [==============================] - 66s 955ms/step - loss: 0.1951 - acc: 0.9311 - val_loss: 0.2251 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.22484\n",
            "Epoch 78/100\n",
            "69/69 [==============================] - 66s 953ms/step - loss: 0.2222 - acc: 0.9207 - val_loss: 0.2250 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00078: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.22484\n",
            "Epoch 79/100\n",
            "69/69 [==============================] - 67s 972ms/step - loss: 0.1973 - acc: 0.9312 - val_loss: 0.2250 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.22484\n",
            "Epoch 80/100\n",
            "69/69 [==============================] - 66s 950ms/step - loss: 0.2025 - acc: 0.9315 - val_loss: 0.2250 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.22484\n",
            "Epoch 81/100\n",
            "69/69 [==============================] - 65s 948ms/step - loss: 0.2017 - acc: 0.9266 - val_loss: 0.2250 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.22484\n",
            "Epoch 82/100\n",
            "69/69 [==============================] - 66s 953ms/step - loss: 0.2014 - acc: 0.9284 - val_loss: 0.2251 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.22484\n",
            "Epoch 83/100\n",
            "69/69 [==============================] - 66s 954ms/step - loss: 0.1941 - acc: 0.9297 - val_loss: 0.2251 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.22484\n",
            "Epoch 84/100\n",
            "69/69 [==============================] - 66s 954ms/step - loss: 0.2102 - acc: 0.9289 - val_loss: 0.2252 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00084: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.22484\n",
            "Epoch 85/100\n",
            "69/69 [==============================] - 66s 955ms/step - loss: 0.2034 - acc: 0.9289 - val_loss: 0.2252 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.22484\n",
            "Epoch 86/100\n",
            "69/69 [==============================] - 66s 954ms/step - loss: 0.2071 - acc: 0.9256 - val_loss: 0.2252 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.22484\n",
            "Epoch 87/100\n",
            "69/69 [==============================] - 66s 954ms/step - loss: 0.2301 - acc: 0.9234 - val_loss: 0.2253 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00087: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.22484\n",
            "Epoch 88/100\n",
            "69/69 [==============================] - 66s 954ms/step - loss: 0.2085 - acc: 0.9257 - val_loss: 0.2252 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.22484\n",
            "Epoch 89/100\n",
            "69/69 [==============================] - 66s 956ms/step - loss: 0.1910 - acc: 0.9311 - val_loss: 0.2252 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.22484\n",
            "Epoch 90/100\n",
            "69/69 [==============================] - 66s 957ms/step - loss: 0.2110 - acc: 0.9238 - val_loss: 0.2252 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00090: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.22484\n",
            "Epoch 91/100\n",
            "69/69 [==============================] - 66s 957ms/step - loss: 0.1945 - acc: 0.9293 - val_loss: 0.2252 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.22484\n",
            "Epoch 92/100\n",
            "69/69 [==============================] - 66s 955ms/step - loss: 0.2213 - acc: 0.9252 - val_loss: 0.2251 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.22484\n",
            "Epoch 93/100\n",
            "69/69 [==============================] - 67s 970ms/step - loss: 0.1939 - acc: 0.9320 - val_loss: 0.2252 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00093: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.22484\n",
            "Epoch 94/100\n",
            "69/69 [==============================] - 66s 957ms/step - loss: 0.2081 - acc: 0.9307 - val_loss: 0.2251 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.22484\n",
            "Epoch 95/100\n",
            "69/69 [==============================] - 66s 957ms/step - loss: 0.1978 - acc: 0.9288 - val_loss: 0.2251 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.22484\n",
            "Epoch 96/100\n",
            "69/69 [==============================] - 66s 954ms/step - loss: 0.1863 - acc: 0.9307 - val_loss: 0.2251 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00096: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.22484\n",
            "Epoch 97/100\n",
            "69/69 [==============================] - 66s 957ms/step - loss: 0.2133 - acc: 0.9248 - val_loss: 0.2251 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.22484\n",
            "Epoch 98/100\n",
            "69/69 [==============================] - 66s 958ms/step - loss: 0.1815 - acc: 0.9415 - val_loss: 0.2250 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.22484\n",
            "Epoch 99/100\n",
            "69/69 [==============================] - 66s 958ms/step - loss: 0.2261 - acc: 0.9175 - val_loss: 0.2250 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00099: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.22484\n",
            "Epoch 100/100\n",
            "69/69 [==============================] - 66s 960ms/step - loss: 0.2099 - acc: 0.9289 - val_loss: 0.2250 - val_acc: 0.9157\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.22484\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtr71Jbpkeo1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "5237062e-0067-4208-e9e4-4553798bf657"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#plt.subplots(2,1)\n",
        "#plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.title(\"Model accuracy\")\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "#plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlPJxmgiUUsrHaSJQSikf9/8BCt7t/BkWvPAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSik/p4FAKaX8nAYCpZTycxoIlFLKz/1/2IBAh/QNi2MAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4vYd6e0szBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "net = load_model(\"/content/res_aug.h5\")\n",
        "\n",
        "predictions = net.predict(xtest)\n",
        "temp = predictions\n",
        "predictions = np.argmax(predictions, axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9PpTuzqtlaS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "27c01683-83db-4c15-aedb-11472104a43f"
      },
      "source": [
        "sam_sub[\"healthy\"].values[:] = 0\n",
        "sam_sub[\"multiple_diseases\"].values[:] = 0\n",
        "sam_sub[\"rust\"].values[:] = 0\n",
        "sam_sub[\"scab\"].values[:] = 0\n",
        "\n",
        "for i in range(len(predictions)):\n",
        "  if predictions[i] == 0:\n",
        "    sam_sub[\"scab\"].values[i] = 1\n",
        "  elif predictions[i] == 1:\n",
        "    sam_sub[\"multiple_diseases\"].values[i] = 1\n",
        "  elif predictions[i] == 2:\n",
        "    sam_sub[\"healthy\"].values[i] = 1\n",
        "  elif predictions[i] == 3:\n",
        "    sam_sub[\"rust\"].values[i] = 1\n",
        "\n",
        "sam_sub.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>healthy</th>\n",
              "      <th>multiple_diseases</th>\n",
              "      <th>rust</th>\n",
              "      <th>scab</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Test_0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Test_1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Test_2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Test_3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Test_4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image_id  healthy  multiple_diseases  rust  scab\n",
              "0   Test_0      0.0                0.0   1.0   0.0\n",
              "1   Test_1      0.0                0.0   1.0   0.0\n",
              "2   Test_2      0.0                0.0   0.0   1.0\n",
              "3   Test_3      1.0                0.0   0.0   0.0\n",
              "4   Test_4      0.0                0.0   1.0   0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7DB5cm533vO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sam_sub.to_csv(\"/content/res_aug.csv\", index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}